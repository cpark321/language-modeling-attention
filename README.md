# language-modeling-attention

- Introductory   
  1. Tutorial on packing sequence in pytorch, BLEU score
  2. Encoder-Decoder with Attention 
  
- Dependencies
  - Python 3.6+
  - PyTorch==1.3
  - Codes are heavily inspired by [https://bastings.github.io/]

### Reference
1. [https://bastings.github.io/]: (https://bastings.github.io/annotated_encoder_decoder/)
